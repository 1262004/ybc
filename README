YBC - Yet another Blob Cache library.

This library implements fast in-process blob cache.


===============================================================================

YBC features.

* Huge amounts of data can be cached. Cache size may be much larger than
  the available RAM size.
  + Very large keys and values are supported (up to 2^64 bytes each).
  + Very large cache size is supported (up to 2^64 items and up to 2^64 bytes).
    In practice cache size is limited by free space on backing store.
  32-bit platforms have much smaller limits (2^32), so use 32-bit builds
  only if your cache fits 4GB.

* Data file layout is optimized for HDD and SSD devices. The code
  prefers sequential I/O instead of random I/O. If random I/O is inevitable,
  the code tries hard localizing it in the smallest possible range.

* Persistence support. Cache data survives process restart if the cache
  is explicitly backed by files.

* Automatic robust recovery from corrupted index files. Corruptions in data
  files may be left unnoticed due to performance reasons - it may be very
  expensive validating multi-GB blobs on every access.

* Dogpile effect (aka 'thundering herd') handling support.

* Cache data may be sharded among available backing store devices.
  Such sharding may linearly increase cache performance if frequently accessed
  items don't fit available physical RAM.

* Multithreading support. The library is thread-safe out of the box
  unless it is compiled with YBC_SINGLE_THREADED macro defined.

* Atomic updates. It is safe updating an item while other threads are reading
  an old value for the item under the same key.

* 'Add transaction' support, which allows constructing item's value on the fly
  without serializing it into a temporary buffer before its' addition into
  the cache. Uncommited transaction can be rolled back at any time.
  Think of media files streamed from the backend or complex objects, which
  require serialization from multiple distinct places before storing into
  the cache.

* Readers and writers don't block each other while reading/writing blobs
  from/into the cache. The speed is actually limited by hardware memory
  bandwidth (if frequently accessed items fit RAM) or backing store
  random I/O bandwidth (if requently accessed items don't fit RAM).

* Instant invalidation of all items in the cache irregardless of cache size.

* Optimization for multi-tiered memory hierarchy in modern CPUs. The code avoids
  unnecessary random memory accesses and tightly packs frequently accessed data
  in order to reduce working set size and increase CPU cache hit ratio.

* The code avoids using dynamic memory allocations in frequently executed paths,
  so cache performance is almost independent of the efficiency of the provided
  malloc() implementation.

* The code avoids using system calls in frequently executed paths.

* The code depends only on OS-supplied libraries.

* The code can be easily ported to new platforms. All platform-specific
  functions and types are hidden behind platform-independent wrappers.

* Public interface (ybc.h) is designed with future versions' compatibility
  in mind. It doesn't expose private structures' contents, so they can be freely
  modified in the future versions of the library without breaking applications
  dynamically linked against older versions.

* Small library size (can be packed to 18Kb with -Os).


===============================================================================

Use-cases.

* CDN cache.

* File hosting cache.

* Memcache-like shared cache.

* Per-process local cache in web-servers.

* Web-proxy or web-accelerator cache.

* Web-browser cache.

* Out-of-GC blob cache for programming languages with GC support.


================================================================================

Credits.

YBC design is inspired by Varnish's "Notes from the Architect" -
https://www.varnish-cache.org/trac/wiki/ArchitectNotes .
